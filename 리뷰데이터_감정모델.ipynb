{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af488619",
   "metadata": {},
   "source": [
    "### 크롤링 코드\n",
    "현대자동차의 차종별 오너평가의 리뷰를 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import urllib.request as req\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "User_Agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\"\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(f\"user-agent={User_Agent }\")\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "car_list = list()\n",
    "                          \n",
    "for i in car['차종'][:3]:\n",
    "    driver.get('https://www.naver.com/')\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    keyword = i + ' 오너평가'\n",
    "\n",
    "    search = driver.find_element(By.CSS_SELECTOR,'#query')\n",
    "    search.send_keys(keyword)\n",
    "    search.send_keys('\\n')\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        # 스크롤을 내리고자 하는 div 요소를 찾기 (XPath는 변경해야 함)\n",
    "        scrollable_div = driver.find_element(By.XPATH, \"/html/body/div[3]/div[2]/div/div[1]/div[2]/div[2]/div/div/div[5]\")\n",
    "\n",
    "        # 이전 스크롤 위치 초기화\n",
    "        last_scroll_position = -1\n",
    "\n",
    "        while True:\n",
    "            # 현재 스크롤 위치 확인\n",
    "            current_scroll_position = driver.execute_script(\"return arguments[0].scrollTop\", scrollable_div)\n",
    "\n",
    "            # 스크롤을 끝까지 내렸는지 확인\n",
    "            if current_scroll_position == last_scroll_position:\n",
    "                break\n",
    "\n",
    "            # 스크롤을 끝까지 내림\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_div)\n",
    "\n",
    "            # 현재 스크롤 위치를 이전 스크롤 위치로 업데이트\n",
    "            last_scroll_position = current_scroll_position\n",
    "\n",
    "            # 스크롤이 완료될 때까지 대기\n",
    "            time.sleep(1)  # 적절한 대기 시간을 설정하세요\n",
    "        time.sleep(10)\n",
    "        person = list()\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR,'#cbox_module_wai_u_cbox_content_wrap_tabpanel > ul > li')\n",
    "        for review in reviews:\n",
    "            person.append(review.text)\n",
    "        \n",
    "        car_list.append(person)\n",
    "    except:\n",
    "        car_list.append([])\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752f86f",
   "metadata": {},
   "source": [
    "### 트위터 감정 데이터 전처리\n",
    "Kaggle의 tweet_emotion 데이터를 이용해 감정 모델을 구축 <br/>\n",
    "-> RoBERTa모델로 ①content + ② sentiment의 관계를 학습시키기 위해 텍스트 전처리와 라벨링을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b68313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 코드\n",
    "\n",
    "def clean_text(val):\n",
    "    val = misspelled_correction(val)\n",
    "    val = cont_to_meaning(val)\n",
    "    val = p.clean(val)\n",
    "    val = ' '.join(punctuation(emoji.demojize(val)).split())\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d0e47",
   "metadata": {},
   "source": [
    "### 리뷰 데이터 전처리\n",
    "트위터 데이터 전처리를 위해 사용했던 함수를 이용해 전처리 수행<br/>\n",
    "현재 리뷰 데이터는 한글로 작성되어 있기 때문에 트위터 데이터를 활용한 모델에 적용시키기 위해서는 영어로 번역하는 과정을 거쳐야 함<br/>\n",
    "Google Translate API를 이용해 번역 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb83976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_en(text,target_language='en'):\n",
    "    print(text)\n",
    "\n",
    "    # Fake User Agent 생성\n",
    "    user_agent = UserAgent()\n",
    "    headers = {'User-Agent': user_agent.random}\n",
    "\n",
    "    # Google Translate URL 및 매개변수 설정\n",
    "    translate_url = 'https://translate.googleapis.com/translate_a/single'\n",
    "    params = {\n",
    "        'client': 'gtx',\n",
    "        'sl': 'auto',\n",
    "        'tl': target_language,\n",
    "        'dt': 't',\n",
    "        'q': text,\n",
    "    }\n",
    "\n",
    "    # HTTP 요청 보내기\n",
    "    response = requests.get(translate_url, params=params, headers=headers)\n",
    "\n",
    "    # 결과 출력\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        translated_text = result[0][0][0]\n",
    "        print(f'Translated Text ({target_language}): {translated_text}')\n",
    "    else:\n",
    "        print(f'Error: {response.status_code}')\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044964e4",
   "metadata": {},
   "source": [
    "### 모델링\n",
    "RoBERTa모델을 이용해 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f8a1b",
   "metadata": {},
   "source": [
    "1) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_attention_mask=False,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        #padding=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "\n",
    "    return np.array(enc_di['input_ids'])\n",
    "\n",
    "def build_model(transformer, max_len=160):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(3, activation='softmax')(cls_token)\n",
    "\n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "MODEL = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL) # MODEL에서의 토크나이저를 정의\n",
    "\n",
    "X_train_t = regular_encode(X_train.values.tolist(), tokenizer, maxlen=max_len)\n",
    "X_test_t = regular_encode(X_test.values.tolist(), tokenizer, maxlen=max_len)\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_train_t, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(1995)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_test_t, y_test))\n",
    "    .batch(batch_size)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n",
    "transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "\n",
    "model_roberta_base = build_model(transformer_layer, max_len=max_len)\n",
    "model_roberta_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377df83",
   "metadata": {},
   "source": [
    "2) 모델학습<br/>\n",
    "트위터 데이터로 학습된 모델을 사용하여 review에서 positive, neutral, negative가 나올 확률 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train.shape[0] // batch_size\n",
    "with tf.device('/gpu:0'):\n",
    "  model_roberta_base.fit(train_dataset,steps_per_epoch=n_steps,validation_data=valid_dataset,epochs=Epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a8098",
   "metadata": {},
   "source": [
    "3) sentiment 확률값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment2(model,text):\n",
    "    text = clean_text(text)\n",
    "    #tokenize\n",
    "    x_test1 = regular_encode([text], tokenizer, maxlen=max_len)\n",
    "    test1 = (tf.data.Dataset.from_tensor_slices(x_test1).batch(1))\n",
    "    #test1\n",
    "    sentiment = model.predict(test1,verbose = 0)\n",
    "    sent = np.round(np.dot(sentiment,100).tolist(),0)[0]\n",
    "    result = pd.DataFrame([sent_to_id.keys(),sent]).T\n",
    "    result.columns = [\"sentiment\",\"percentage\"]\n",
    "    result=result[result.percentage !=0]\n",
    "    return result\n",
    "\n",
    "ex)\n",
    "result =get_sentiment2(model_roberta_base,\"I hate this game so much,It make me angry all the time \")\n",
    "# positive -> 19.0 / negative-> 81.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a10116",
   "metadata": {},
   "source": [
    "4) 리뷰데이터에 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num,i in enumerate(review['en']):\n",
    "  result =get_sentiment2(model_roberta_base,i)\n",
    "  review['result_dict_robert'][num] = dict(zip(result['sentiment'],result['percentage']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
